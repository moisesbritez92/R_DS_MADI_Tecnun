# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ“Š CHULETA DE R - ANÃLISIS DE DATOS Y ESTADÃSTICA
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Fecha: Octubre 2025
# Basada en ejercicios de visualizaciÃ³n y anÃ¡lisis de datos en R
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# ===============================================================================
# ğŸ“¦ 1. LIBRERÃAS ESENCIALES
# ===============================================================================

# ManipulaciÃ³n de datos
library(dplyr)        # ManipulaciÃ³n de datos (group_by, summarise, filter, mutate)
library(tidyr)        # ReestructuraciÃ³n de datos (pivot_longer, pivot_wider)
library(stringr)      # ManipulaciÃ³n de strings (str_replace, str_detect)
library(readr)        # Lectura rÃ¡pida de datos

# VisualizaciÃ³n
library(ggplot2)      # GrÃ¡ficos avanzados
library(viridis)      # Paletas de colores
library(ggrepel)      # Etiquetas sin solapamiento
library(gridExtra)    # MÃºltiples grÃ¡ficos

# Texto y NLP
library(tm)           # Text mining (removePunctuation, removeWords, stopwords)
library(textstem)     # LemmatizaciÃ³n (lemmatize_words)

# EstadÃ­stica
library(pwr)          # AnÃ¡lisis de potencia estadÃ­stica

# ===============================================================================
# ğŸ“‚ 2. CARGA Y EXPLORACIÃ“N DE DATOS
# ===============================================================================

# 2.1 Cargar datos
data <- read.csv('./data/archivo.csv', 
                 header = TRUE,              # Primera fila son nombres
                 sep = ',',                  # Separador
                 stringsAsFactors = FALSE,   # No convertir strings a factores
                 check.names = FALSE,        # Mantener nombres originales
                 fileEncoding = 'latin1')    # Encoding para caracteres especiales

# 2.2 ExploraciÃ³n bÃ¡sica
head(data)              # Primeras 6 filas
tail(data, 10)          # Ãšltimas 10 filas
str(data)               # Estructura del dataset
summary(data)           # Resumen estadÃ­stico
dim(data)               # Dimensiones (filas x columnas)
colnames(data)          # Nombres de columnas
nrow(data)              # NÃºmero de filas
ncol(data)              # NÃºmero de columnas

# 2.3 Valores Ãºnicos y frecuencias
unique(data$columna)                    # Valores Ãºnicos
length(unique(data$columna))            # NÃºmero de valores Ãºnicos
table(data$columna)                     # Tabla de frecuencias
sort(table(data$columna), decreasing = TRUE)  # Frecuencias ordenadas

# ===============================================================================
# ğŸ§¹ 3. LIMPIEZA DE DATOS
# ===============================================================================

# 3.1 Eliminar columnas
data <- data[, -2]                      # Eliminar segunda columna
data <- data[, -c(3, 4, 5)]            # Eliminar columnas 3, 4 y 5
data <- data %>% select(-columna_x)     # Eliminar por nombre

# 3.2 Renombrar columnas
colnames(data) <- c('Col1', 'Col2', 'Col3')
data <- data %>% rename(nuevo = antiguo)

# 3.3 Missing values
sum(is.na(data))                        # Total de NAs
sapply(data, function(x) sum(is.na(x))) # NAs por columna
data_clean <- na.omit(data)             # Eliminar filas con NAs
data$col[is.na(data$col)] <- 0         # Reemplazar NAs con 0

# 3.4 ConversiÃ³n de tipos
data$col <- as.numeric(data$col)
data$col <- as.character(data$col)
data$col <- as.factor(data$col)
data$col <- as.Date(data$col)

# 3.5 Limpiar strings
data$col <- tolower(data$col)                           # A minÃºsculas
data$col <- toupper(data$col)                           # A mayÃºsculas
data$col <- gsub("\\.", "", data$col)                   # Eliminar puntos
data$col <- str_replace(data$col, "^[0-9]+[\\. ]*", "") # Eliminar cÃ³digos numÃ©ricos
data$col <- str_trim(data$col)                          # Eliminar espacios

# ===============================================================================
# ğŸ”„ 4. MANIPULACIÃ“N DE DATOS (dplyr)
# ===============================================================================

# 4.1 Filtrar (filter)
data %>% filter(columna > 100)
data %>% filter(columna == "valor")
data %>% filter(columna %in% c("A", "B", "C"))
data %>% filter(col1 > 10 & col2 == "X")
data %>% filter(col1 > 10 | col2 == "X")
data %>% filter(!is.na(columna))

# 4.2 Seleccionar columnas (select)
data %>% select(col1, col2, col3)
data %>% select(-col_eliminar)
data %>% select(starts_with("pre"))
data %>% select(ends_with("sufijo"))
data %>% select(contains("texto"))

# 4.3 Crear nuevas columnas (mutate)
data %>% mutate(nueva = col1 + col2)
data %>% mutate(
  nueva1 = col1 * 2,
  nueva2 = log(col2),
  nueva3 = ifelse(col3 > 10, "Alto", "Bajo")
)

# 4.4 Condicionales (case_when)
data %>% mutate(
  categoria = case_when(
    valor < 10 ~ "Bajo",
    valor < 50 ~ "Medio",
    valor >= 50 ~ "Alto",
    TRUE ~ "Desconocido"  # Caso por defecto
  )
)

# 4.5 Agrupar y resumir (group_by + summarise)
data %>%
  group_by(categoria) %>%
  summarise(
    n = n(),                           # Contar filas
    media = mean(valor, na.rm = TRUE),
    mediana = median(valor, na.rm = TRUE),
    desv_std = sd(valor, na.rm = TRUE),
    minimo = min(valor, na.rm = TRUE),
    maximo = max(valor, na.rm = TRUE),
    suma = sum(valor, na.rm = TRUE),
    .groups = "drop"                   # Desagrupar al final
  )

# 4.6 Ordenar (arrange)
data %>% arrange(columna)              # Ascendente
data %>% arrange(desc(columna))        # Descendente
data %>% arrange(col1, desc(col2))     # MÃºltiples criterios

# 4.7 Combinar datasets
merge(df1, df2, by = "id")                        # Inner join
merge(df1, df2, by = "id", all.x = TRUE)          # Left join
merge(df1, df2, by = "id", all.y = TRUE)          # Right join
merge(df1, df2, by = "id", all = TRUE)            # Full join
df1 %>% inner_join(df2, by = "id")                # dplyr inner join
df1 %>% left_join(df2, by = c("col1" = "col2"))   # Join con diferentes nombres

# ===============================================================================
# ğŸ”€ 5. REESTRUCTURACIÃ“N DE DATOS (tidyr)
# ===============================================================================

# 5.1 De ancho a largo (pivot_longer)
data_long <- data %>%
  pivot_longer(
    cols = c(col1, col2, col3),        # Columnas a convertir
    names_to = "variable",             # Nombre de la columna de nombres
    values_to = "valor"                # Nombre de la columna de valores
  )

# Ejemplo: convertir aÃ±os en columnas a formato largo
data %>%
  pivot_longer(
    cols = -Comunidad,                 # Todas excepto Comunidad
    names_to = "AÃ±o",
    values_to = "Poblacion"
  )

# 5.2 De largo a ancho (pivot_wider)
data_wide <- data %>%
  pivot_wider(
    names_from = variable,
    values_from = valor
  )

# ===============================================================================
# ğŸ“Š 6. VISUALIZACIÃ“N (ggplot2)
# ===============================================================================

# 6.1 Estructura bÃ¡sica de ggplot2
ggplot(data, aes(x = col_x, y = col_y)) +
  geom_point() +                       # Tipo de grÃ¡fico
  labs(title = "TÃ­tulo",               # Etiquetas
       x = "Eje X",
       y = "Eje Y") +
  theme_minimal()                      # Tema

# 6.2 GrÃ¡fico de lÃ­neas
ggplot(data, aes(x = year, y = value, color = category, group = category)) +
  geom_line(size = 1.2) +
  geom_point(size = 2) +
  scale_color_viridis_d() +            # Colores discretos
  theme_minimal()

# 6.3 GrÃ¡fico de barras
# Barras simples
ggplot(data, aes(x = categoria, y = valor)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  coord_flip()                         # Barras horizontales

# Barras agrupadas
ggplot(data, aes(x = categoria, y = valor, fill = grupo)) +
  geom_bar(stat = "identity", position = "dodge", alpha = 0.8)

# Barras apiladas
ggplot(data, aes(x = categoria, y = valor, fill = grupo)) +
  geom_bar(stat = "identity", position = "stack")

# 6.4 Boxplot
ggplot(data, aes(x = categoria, y = valor, fill = categoria)) +
  geom_boxplot(alpha = 0.7) +
  scale_fill_manual(values = c("A" = "steelblue", "B" = "coral"))

# 6.5 Scatter plot
ggplot(data, aes(x = var1, y = var2, color = categoria, size = var3)) +
  geom_point(alpha = 0.7) +
  geom_smooth(method = "lm", se = TRUE, color = "red") +  # LÃ­nea de tendencia
  scale_size_continuous(range = c(2, 8))

# 6.6 Facetas (mÃºltiples grÃ¡ficos)
ggplot(data, aes(x = x, y = y)) +
  geom_line() +
  facet_wrap(~ categoria, scales = "free_y")  # scales: "free", "free_x", "free_y"

ggplot(data, aes(x = x, y = y)) +
  geom_point() +
  facet_grid(rows = vars(categoria1), cols = vars(categoria2))

# 6.7 PersonalizaciÃ³n avanzada
ggplot(data, aes(x = x, y = y, color = grupo)) +
  geom_point(alpha = 0.7, size = 2) +
  stat_ellipse(aes(fill = grupo), alpha = 0.2, geom = "polygon") +  # Elipses
  geom_text_repel(aes(label = etiqueta), size = 3, max.overlaps = 15) +  # Etiquetas
  scale_color_manual(values = c("A" = "steelblue", "B" = "coral")) +
  scale_y_continuous(labels = scales::percent) +  # Eje en porcentaje
  scale_x_continuous(breaks = seq(1980, 2000, 5)) +  # Breaks personalizados
  labs(
    title = "TÃ­tulo Principal",
    subtitle = "SubtÃ­tulo informativo",
    x = "Eje X",
    y = "Eje Y",
    color = "Leyenda",
    caption = "Fuente: Datos"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(face = "bold", size = 14),
    plot.subtitle = element_text(size = 11, color = "gray40"),
    legend.position = "bottom",
    axis.text.x = element_text(angle = 45, hjust = 1)
  )

# 6.8 Guardar grÃ¡ficos
ggsave("grafico.png", width = 10, height = 6, dpi = 300)

# ===============================================================================
# ğŸ“ˆ 7. ANÃLISIS ESTADÃSTICO
# ===============================================================================

# 7.1 EstadÃ­sticas descriptivas
mean(data$col, na.rm = TRUE)           # Media
median(data$col, na.rm = TRUE)         # Mediana
sd(data$col, na.rm = TRUE)             # DesviaciÃ³n estÃ¡ndar
var(data$col, na.rm = TRUE)            # Varianza
quantile(data$col, probs = c(0.25, 0.5, 0.75))  # Cuartiles
IQR(data$col, na.rm = TRUE)            # Rango intercuartÃ­lico

# 7.2 Test t de Student (comparar medias)
# Test de una muestra
t.test(data$variable, mu = 10)         # H0: media = 10

# Test de dos muestras independientes
t.test(valor ~ grupo, data = data)     # Comparar dos grupos
t.test(data$grupo1, data$grupo2)       # Alternativa

# Test pareado
t.test(data$antes, data$despues, paired = TRUE)

# Extraer resultados
resultado <- t.test(valor ~ grupo, data = data)
resultado$statistic                     # EstadÃ­stico t
resultado$p.value                       # P-valor
resultado$conf.int                      # Intervalo de confianza
resultado$estimate                      # Estimaciones

# 7.3 CorrelaciÃ³n
cor(data$var1, data$var2)              # CorrelaciÃ³n de Pearson
cor(data$var1, data$var2, method = "spearman")  # Spearman (no paramÃ©trica)

# Test de correlaciÃ³n
cor_test <- cor.test(data$var1, data$var2)
cor_test$estimate                       # Coeficiente de correlaciÃ³n
cor_test$p.value                        # P-valor
cor_test$conf.int                       # Intervalo de confianza

# 7.4 Test de Fisher (tablas de contingencia)
# Crear tabla de contingencia
tabla <- matrix(c(20, 10, 15, 25), nrow = 2)

# Test de Fisher
fisher.test(tabla, alternative = "greater")  # "greater", "less", "two.sided"

# Con datos reales
tabla <- table(data$var1, data$var2)
fisher.test(tabla)

# 7.5 Chi-cuadrado (independencia)
chisq.test(tabla)

# 7.6 ANOVA (comparar mÃ¡s de dos grupos)
anova_result <- aov(valor ~ grupo, data = data)
summary(anova_result)

# Test post-hoc (comparaciones mÃºltiples)
TukeyHSD(anova_result)

# 7.7 RegresiÃ³n lineal
modelo <- lm(y ~ x, data = data)
summary(modelo)                         # Resumen del modelo
coef(modelo)                            # Coeficientes
confint(modelo)                         # Intervalos de confianza
predict(modelo, newdata = datos_nuevos) # Predicciones

# RegresiÃ³n mÃºltiple
modelo_multi <- lm(y ~ x1 + x2 + x3, data = data)
summary(modelo_multi)

# ===============================================================================
# ğŸ² 8. CORRECCIÃ“N POR COMPARACIONES MÃšLTIPLES
# ===============================================================================

# Cuando se realizan mÃºltiples tests estadÃ­sticos, hay que ajustar p-values

# 8.1 MÃ©todos de ajuste
p_values <- c(0.01, 0.03, 0.05, 0.08, 0.12)

# Bonferroni (muy conservador)
p.adjust(p_values, method = "bonferroni")

# Benjamini-Hochberg / FDR (recomendado)
p.adjust(p_values, method = "BH")

# Holm (menos conservador que Bonferroni)
p.adjust(p_values, method = "holm")

# 8.2 AplicaciÃ³n prÃ¡ctica
resultados <- data.frame(
  estado = c("A", "B", "C", "D"),
  p_value = c(0.01, 0.03, 0.05, 0.08)
)

resultados$p_adjusted <- p.adjust(resultados$p_value, method = "BH")
resultados$significativo <- resultados$p_adjusted < 0.05

# ===============================================================================
# ğŸ”¬ 9. ANÃLISIS DE COMPONENTES PRINCIPALES (PCA)
# ===============================================================================

# 9.1 Realizar PCA
# Preparar matriz (solo variables numÃ©ricas)
matriz <- data %>% select(var1, var2, var3, var4) %>% as.matrix()

# PCA
pca <- prcomp(matriz, scale. = TRUE, center = TRUE)

# 9.2 Extraer informaciÃ³n
# Varianza explicada
varianza_explicada <- summary(pca)$importance[2, 1:2] * 100
cat("PC1 explica:", round(varianza_explicada[1], 2), "%\n")
cat("PC2 explica:", round(varianza_explicada[2], 2), "%\n")

# Componentes principales (scores)
pca_scores <- pca$x[, 1:2]              # Primeros 2 componentes

# Loadings (contribuciÃ³n de cada variable)
loadings <- pca$rotation[, 1:2]
pc1_loadings <- abs(pca$rotation[, 1])
top_pc1 <- head(sort(pc1_loadings, decreasing = TRUE), 5)

# 9.3 Visualizar PCA
pca_df <- data.frame(
  PC1 = pca$x[, 1],
  PC2 = pca$x[, 2],
  grupo = data$categoria
)

ggplot(pca_df, aes(x = PC1, y = PC2, color = grupo)) +
  geom_point(alpha = 0.7, size = 2) +
  stat_ellipse(aes(fill = grupo), alpha = 0.2, geom = "polygon") +
  labs(
    title = "AnÃ¡lisis de Componentes Principales (PCA)",
    x = paste("PC1 (", round(varianza_explicada[1], 1), "%)"),
    y = paste("PC2 (", round(varianza_explicada[2], 1), "%)")
  ) +
  theme_minimal()

# 9.4 Biplot (variables + observaciones)
# Extraer loadings
loadings_df <- data.frame(
  Variable = rownames(loadings),
  PC1 = loadings[, 1],
  PC2 = loadings[, 2]
)

scale_factor <- 3  # Factor de escala para flechas

ggplot() +
  geom_point(data = pca_df, aes(x = PC1, y = PC2, color = grupo), alpha = 0.7) +
  geom_segment(data = loadings_df, 
               aes(x = 0, y = 0, xend = PC1 * scale_factor, yend = PC2 * scale_factor),
               arrow = arrow(length = unit(0.2, "cm")), color = "red") +
  geom_text_repel(data = loadings_df, 
                  aes(x = PC1 * scale_factor, y = PC2 * scale_factor, label = Variable),
                  color = "red", size = 3.5) +
  theme_minimal()

# ===============================================================================
# ğŸ’ª 10. ANÃLISIS DE POTENCIA ESTADÃSTICA
# ===============================================================================

# 10.1 Test de correlaciÃ³n
# Â¿CuÃ¡l es la potencia con n=12 para detectar r=0.5?
power_result <- pwr.r.test(n = 12, r = 0.5, sig.level = 0.05)
power_result$power

# Â¿QuÃ© n necesito para power=0.8 con r=0.5?
n_result <- pwr.r.test(r = 0.5, sig.level = 0.05, power = 0.8)
ceiling(n_result$n)

# 10.2 Test t
# Para test t de dos muestras independientes
pwr.t.test(n = 30, d = 0.5, sig.level = 0.05, type = "two.sample")

# 10.3 ANOVA
pwr.anova.test(k = 3, n = 20, f = 0.25, sig.level = 0.05)

# 10.4 Proporciones
pwr.2p.test(h = 0.3, n = 100, sig.level = 0.05)

# ===============================================================================
# ğŸ“ 11. PROCESAMIENTO DE TEXTO (NLP)
# ===============================================================================

# 11.1 Limpieza bÃ¡sica
texto <- "ESTE es un TEXTO de Ejemplo... con 123 nÃºmeros!"

texto_clean <- texto %>%
  tolower() %>%                         # MinÃºsculas
  removePunctuation() %>%               # Quitar puntuaciÃ³n
  removeNumbers() %>%                   # Quitar nÃºmeros
  removeWords(stopwords("english"))     # Quitar stopwords

# 11.2 Stopwords (palabras comunes sin significado)
stopwords("english")                    # InglÃ©s
stopwords("spanish")                    # EspaÃ±ol

# 11.3 LemmatizaciÃ³n (reducir a forma base)
palabras <- c("running", "ran", "runs", "driving", "drove")
lemmatize_words(palabras)              # "run", "run", "run", "drive", "drive"

# 11.4 Crear matriz documento-tÃ©rmino
corpus <- VCorpus(VectorSource(data$texto))

# Crear matriz
tdm <- TermDocumentMatrix(corpus, control = list(wordLengths = c(3, Inf)))
matriz_texto <- t(as.matrix(tdm))      # Transponer (filas = documentos)

# Filtrar palabras por frecuencia
word_freq <- colSums(matriz_texto)
palabras_frecuentes <- names(word_freq[word_freq >= 50])
matriz_filtrada <- matriz_texto[, palabras_frecuentes]

# ===============================================================================
# ğŸ”¢ 12. EXPRESIONES REGULARES (regex)
# ===============================================================================

# Detectar patrones
str_detect("texto123", "[0-9]+")       # TRUE si contiene nÃºmeros
str_detect("email@test.com", "@")      # TRUE si contiene @

# Reemplazar
str_replace("texto123", "[0-9]+", "")  # Eliminar nÃºmeros
str_replace_all("a-b-c", "-", "_")     # Reemplazar todos

# Extraer
str_extract("precio: 25.50", "[0-9.]+")  # Extraer nÃºmero

# Patrones comunes
"^[0-9]+"           # NÃºmeros al inicio
"[0-9]+$"           # NÃºmeros al final
"[^0-9]"            # Cualquier cosa que NO sea nÃºmero
"\\."               # Punto literal (escape)
"\\s"               # Espacio en blanco
"[a-zA-Z]+"         # Letras
"[aeiou]"           # Vocales

# ===============================================================================
# ğŸ¯ 13. CONSEJOS Y BUENAS PRÃCTICAS
# ===============================================================================

# 13.1 Pipe operator (%>%)
# En lugar de:
resultado <- arrange(filter(select(data, col1, col2), col1 > 10), col2)

# Mejor:
resultado <- data %>%
  select(col1, col2) %>%
  filter(col1 > 10) %>%
  arrange(col2)

# 13.2 Imprimir con formato
cat("=== TÃTULO ===\n")
cat("Valor:", round(valor, 2), "\n")
cat(paste("Total:", sum(data$col), "\n"))

# 13.3 Crear secuencias
1:10                                    # 1, 2, 3, ..., 10
seq(0, 100, by = 10)                   # 0, 10, 20, ..., 100
seq(0, 1, length.out = 11)             # 11 valores entre 0 y 1

# 13.4 Aplicar funciones
lapply(data, mean)                     # Lista
sapply(data, mean)                     # Vector simplificado
apply(matriz, 1, sum)                  # Por filas (1) o columnas (2)

# 13.5 Condicionales
if(condicion) {
  # cÃ³digo
} else if(otra_condicion) {
  # cÃ³digo
} else {
  # cÃ³digo
}

# ifelse vectorizado
data$categoria <- ifelse(data$valor > 10, "Alto", "Bajo")

# 13.6 Loops
for(i in 1:nrow(data)) {
  # procesar fila i
}

for(nombre in nombres) {
  # procesar nombre
}

# 13.7 Crear funciones
calcular_media <- function(x, quitar_na = TRUE) {
  if(quitar_na) {
    x <- x[!is.na(x)]
  }
  suma <- sum(x)
  n <- length(x)
  return(suma / n)
}

# ===============================================================================
# ğŸ“Š 14. TABLAS DE CONTINGENCIA Y FRECUENCIAS
# ===============================================================================

# Tabla simple
table(data$categoria)

# Tabla de contingencia 2x2
tabla <- table(data$var1, data$var2)
prop.table(tabla)                      # Proporciones
prop.table(tabla, margin = 1)          # Por filas
prop.table(tabla, margin = 2)          # Por columnas

# Agregar totales
addmargins(tabla)

# ===============================================================================
# ğŸ¨ 15. PALETAS DE COLORES
# ===============================================================================

# Colores predefinidos
scale_fill_viridis_d()                 # Discreto
scale_fill_viridis_c()                 # Continuo
scale_color_brewer(palette = "Set1")   # ColorBrewer

# Colores manuales
scale_fill_manual(values = c("A" = "steelblue", "B" = "coral", "C" = "green"))
scale_color_manual(values = c("#FF6B6B", "#4ECDC4", "#45B7D1"))

# ===============================================================================
# ğŸ“Œ 16. ATAJOS DE TECLADO ÃšTILES EN RSTUDIO
# ===============================================================================

# Ctrl + Enter       : Ejecutar lÃ­nea/selecciÃ³n
# Ctrl + Shift + M   : Pipe operator (%>%)
# Ctrl + Shift + C   : Comentar/descomentar
# Alt + -            : Operador asignaciÃ³n (<-)
# Ctrl + L           : Limpiar consola
# Ctrl + Shift + F10 : Reiniciar sesiÃ³n R
# Tab                : Autocompletar

# ===============================================================================
# ğŸ” 17. INTERPRETACIÃ“N DE P-VALUES
# ===============================================================================

# p < 0.001  : Muy significativo (***)
# p < 0.01   : Significativo (**)
# p < 0.05   : Significativo (*)
# p >= 0.05  : No significativo (ns)

# Regla general:
# - Si p < Î± (usualmente 0.05) â†’ Rechazar H0 (hay efecto significativo)
# - Si p â‰¥ Î± â†’ No rechazar H0 (no hay evidencia suficiente)

# ===============================================================================
# ğŸ“ˆ 18. FÃ“RMULAS ESTADÃSTICAS COMUNES
# ===============================================================================

# Media: xÌ„ = Î£x / n
mean(x)

# DesviaciÃ³n estÃ¡ndar: s = âˆš(Î£(x-xÌ„)Â² / (n-1))
sd(x)

# Error estÃ¡ndar: SE = s / âˆšn
sd(x) / sqrt(length(x))

# Intervalo de confianza 95%: xÌ„ Â± 1.96 * SE
media <- mean(x)
se <- sd(x) / sqrt(length(x))
ic_inferior <- media - 1.96 * se
ic_superior <- media + 1.96 * se

# TamaÃ±o del efecto (Cohen's d)
d <- (mean(grupo1) - mean(grupo2)) / sd(c(grupo1, grupo2))

# CorrelaciÃ³n de Pearson: r = Î£((x-xÌ„)(y-È³)) / âˆš(Î£(x-xÌ„)Â² * Î£(y-È³)Â²)
cor(x, y)

# ===============================================================================
# ğŸ“ 19. CONCEPTOS ESTADÃSTICOS CLAVE
# ===============================================================================

# HipÃ³tesis nula (H0): No hay diferencia/efecto
# HipÃ³tesis alternativa (H1): SÃ­ hay diferencia/efecto

# Error Tipo I (Î±): Rechazar H0 cuando es verdadera (falso positivo)
#                   Usualmente Î± = 0.05

# Error Tipo II (Î²): No rechazar H0 cuando es falsa (falso negativo)
#                     Potencia = 1 - Î² (usualmente 0.80)

# FDR (False Discovery Rate): ProporciÃ³n de falsos positivos esperada
#                             Se controla con Benjamini-Hochberg

# Potencia estadÃ­stica: Probabilidad de detectar un efecto si existe
#                       Depende de: tamaÃ±o muestral, tamaÃ±o del efecto, Î±

# ===============================================================================
# ğŸ“š 20. RECURSOS ADICIONALES
# ===============================================================================

# Ayuda en R
?funcion                               # Ayuda de funciÃ³n
??tema                                 # Buscar en toda la documentaciÃ³n
example(funcion)                       # Ver ejemplos

# Cheat sheets oficiales:
# - dplyr: https://dplyr.tidyverse.org/
# - ggplot2: https://ggplot2.tidyverse.org/
# - RStudio: Help > Cheatsheets

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FIN DE LA CHULETA
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
