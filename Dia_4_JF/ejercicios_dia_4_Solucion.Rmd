---
title: "Ejercicios día 4"
output: 
  html_document:
    toc: true
date: "2025-09-30"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Los ejercicios que se presentan en este documento son sobre Visualización y Análisis de Datos en R. Los ejercicios del primer examen se van a parecer a estos ejercicios.

Librerías que vamos a necesitar:

```{r libraries,warning=FALSE,message=FALSE}
library(ggplot2)
library(viridis)
library(ggrepel)
library(dplyr)
library(tm)
library(textstem)
library(pwr)
library(tidyr)
library(stringr)
```

# Ejercicio 1

Importar el reporte hitórico de crimenes en EEUU desde 1977 hasta 1999. Este data set contiene información sobre diferentes tipos de crimenes en los 51 estados durante el periodo de tiempo señalado. Además contiene información sobre la población, renta per capita, etc.

Información sobre estos datos se puede encontrar en el siguiente <a href="https://vincentarelbundock.github.io/Rdatasets/doc/AER/Guns.html" target="_blank">link</a>.


**Cargar crimeUS.csv**

```{r}
data <- read.csv('CrimeUS.csv', header = T, sep = ',', stringsAsFactors = F)
```

### 1.1
**Generar una imagen para visualizar rápidamente qué estados y en que años hubo más robos. En la gráfica se debe poder visualizar la evolución del número de robos para cada estado de forma sencilla**

```{r}
hm1 <- ggplot(data = data, aes(x = state, y = year, fill = robbery)) + geom_tile() +
  theme_minimal() + coord_fixed(ratio = 1, expand = T) + 
  scale_y_discrete(expand = expansion(mult = c(0.01,0.01))) +
  scale_fill_gradientn(colours = inferno(256)) +
  #scale_fill_viridis_c(option='plasma')+
  theme(axis.title.x = element_blank(), axis.title.y = element_blank(), 
        legend.title = element_blank(), plot.title = element_text(hjust = 0.5),
        axis.text.x = element_text(hjust = 0.9, vjust = 0.9, angle = 55), 
        axis.text.y = element_text(hjust = 0.9)) + 
  ggtitle('Number of robberies by state and year')
hm1
```

### 1.2
**Generar una gráfica para visualizar en cada año, el número total de cada tipo de crimen También se pide generar una tabla con esta información**

```{r}
tmp <- aggregate(. ~ year, data = data[,1:4], FUN = sum)
df <- data.frame(year = rep(tmp$year, each = 3), 
                 type = rep(c('violent','murder','robbery'), length(tmp$year)),
                 value = as.vector(as.matrix(t(tmp[,2:4]))))
head(df)
```

```{r}
bp1 <- ggplot(data = df, aes(x = year, y = value, fill = type)) + 
  geom_bar(position = 'stack', stat = 'identity') + theme_classic() + 
  scale_fill_manual(values = c("#999999","#56B4E9","#E69F00")) + 
  scale_y_continuous(expand = expansion(mult = c(0.01,0.02))) +
  theme(axis.title.x = element_blank(), axis.title.y = element_blank(), 
        legend.title = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_rect(colour = "black", size = 1)) +
  ggtitle('Number of crimes by date and type')
bp1
```

### 1.3
**Generar una gráfica para visualizar en cada año, la proporción de cada tipo de crimen.**

```{r}
bp1.2 <- ggplot(data = df, aes(x = year, y = value, fill = type)) + 
  geom_bar(stat = 'identity',position = "fill") + theme_classic() + 
  scale_fill_manual(values = c("#999999","#56B4E9","#E69F00")) + 
  scale_y_continuous(expand = expansion(mult = c(0.01,0.02))) +
  theme(axis.title.x = element_blank(), axis.title.y = element_blank(), 
        legend.title = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_rect(colour = "black", size = 1)) +
  ggtitle('Number of crimes by date and type')
bp1.2
```


### 1.4
**Generar una imagen para visualizar el número de presos que hubo cada año entre 1980 y 1990 distinguiendo entre los estados de Alabama, Arizona y Florida.**

```{r}
df <- data %>%
  filter(state %in% c('Alabama', 'Arizona', 'Florida'),
         year %in% seq(1980, 1990, 1))

bp2 <- ggplot(data = df, aes(x = year, y = prisoners, fill = state)) + 
  geom_bar(position = 'dodge', stat = 'identity') + theme_classic() + 
  scale_y_continuous(expand = expansion(mult = c(0.01,0.02))) +
  scale_x_continuous(breaks = seq(1980,1990,1))+
  theme(axis.title.x = element_blank(), axis.title.y = element_blank(), 
        legend.title = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_rect(colour = "black", size = 1)) +
  ggtitle('Number of prisoners in Alabama, Arizona and Florida by year')
bp2 

```

### 1.5
**¿El número de presos es diferente entre los 3 estados?**

```{r}
anova1 <- aov(prisoners ~ state, df)
summary(anova1)

```

### 1.6
**Generar una imagen para visualizar la distribución del número de robos y prisioneros en cada año, comparando ambas variables simultáneamente.**

```{r}
tmp <- aggregate(. ~ year + state, data = data[, c(1,4,5,12)], FUN = sum)
df <- data.frame(year = rep(tmp$year,2), state = rep(tmp$state,2),
                 values = as.vector(as.matrix(tmp[,3:4])),
                 type = rep(c('robbery','prisoners'), each = length(unique(tmp$year))*length(unique(tmp$state))))
head(df)
```

```{r,warning=FALSE}
df$year <- as.factor(df$year)
bxp1 <- ggplot(data = df, aes(x = year, y = values, fill = type)) + 
  geom_boxplot(outlier.shape = NA) +
  stat_boxplot(geom = 'errorbar') + theme_classic() + 
  theme(axis.title.x = element_blank(), axis.title.y = element_blank(), legend.title = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_rect(colour = "black", size = 1),
        axis.text.y = element_text(size = 10), legend.text = element_text(size = 10), 
        axis.text.x = element_text(size = 10,angle = 90,vjust = 0.5),# axis.ticks.x = element_blank(), 
        plot.title = element_text(hjust = 0.5)) + 
  scale_y_continuous(limits=c(0,60000))+
  ggtitle('Number of robberies and prisoners by year')
bxp1
```


### 1.7

**Ahora nos vamos a centrar en el estado de Nevada. Queremos saber que tipo de crimen tiene mayor correlación con el número de prisioneros. Para realizar el test estadístico correpondiente se puede utilizar la función `cor.test()`. Finalmente, generar una gráfica para visualizar la correlación del ese tipo de crimen con el número de prisioneros**


```{r}
df <- data[data$state %in% 'Nevada',]

cor_violent <- cor.test(df$violent, df$prisoners)
cor_murder <- cor.test(df$murder, df$prisoners)
cor_robbery <- cor.test(df$robbery, df$prisoners)

c_v <- round(cor(df$violent, df$prisoners, method = 'pearson'),2)
c_m <- round(cor(df$murder, df$prisoners, method = 'pearson'),2)
c_r <- round(cor(df$robbery, df$prisoners, method = 'pearson'),2)

```


```{r}
sp1 <- ggplot(data = df, aes(x = violent, y = prisoners)) + 
  geom_point(color = "#1e3a8a", size = 2.5) +  # Azul oscuro para puntos
  geom_smooth(aes(x = violent, y = prisoners), method = 'lm', formula = y ~ x,
              color = "#2563eb", fill = "#60a5fa", alpha = 0.3) +  # Azul vistoso para línea, azul transparente para sombreado
  theme_classic() + 
  theme(axis.title.x = element_text(size = 14), axis.title.y = element_text(size = 14), 
        panel.grid.minor = element_blank(), panel.grid.major = element_blank(),
        panel.background = element_rect(colour = "black", size = 1), legend.title = element_blank(),
        axis.text.y = element_text(size = 13),
        axis.text.x = element_text(size = 13), legend.text = element_text(size = 13)) +
  xlab('Violent crimes') + ylab('Prisoners') + 
  geom_label(aes(x = 5800, y = 10000), label = paste0('R:',as.character(c_v)), 
             show.legend = F, fill = 'white', color = '#2563eb', size = 5)
sp1
```


### 1.8

**Se quiere comprobar para cada estado si el número de asesinatos es diferente entre los años pasados (1977-1988) y los años más recientes(1989-1999). Finalmente, se pide visualizar estos resultados en una gráfica** 

Primero tenemos que crear nuestro subset de datos.
```{r}
df <- matrix(data = data$murder, nrow = length(unique(data$state)), byrow = T)
rownames(df) <- unique(data$state)
colnames(df) <- as.character(unique(data$year))

years <- c(1977, 1978, 1979, 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988)
idx <- !is.element(colnames(df), years)
```


Una vez tenemos los datos, podemos aplicar un t.test para comparar los años "pasados" con los años recientes. Lo podemos hacer con un apply para hacer el test lo más rápido posible.
Tras hacer el t.test, como hemos realizado 51 t.test, es necesario realiar una correción de hipótesis múltiple.

```{r}
pval <- apply(df, 1, function(x) t.test(x[idx],x[!idx], paired = F)$p.value)
pval_corrected <- p.adjust(pval, method = 'BH')
```


Para visualizar estos resultados se puede utilizar el volcano plot. El volcano plot tiene en el eje x el log2 del Fold change y en el eje y tiene $-log_{10}(adjusted.pvalue)$. Como hay 51 estados y no podemos señalar todos los estados (la leyenda de la figura sería muy grande y dificil de entender) vamos a señalizar solo los casos donde hay significancia estadística.

Primero creamos el data.frame con la información para generar la figura:
```{r}
fc <- apply(df,1, function(x) log2(mean(x[idx])/mean(x[!idx])))
df <- data.frame(pval = -log10(pval_corrected), fc = fc)
df$sig <- factor(rep(0,nrow(df)), levels = c(-1,0,1))
df$sig[pval_corrected < 0.05 & fc < -1] <- -1
df$sig[pval_corrected < 0.05 & fc > 1] <- 1
df$lab <- ''
df$lab[df$sig != 0] <- names(pval_corrected)[df$sig != 0]
```


Después, podemos generar el volcano plot:
```{r}
vp1 <- ggplot(data = df) + geom_point(aes(x = fc, y = pval, colour = sig), size = 2.5) + 
  theme_classic() + scale_x_continuous(limits = c((-max(abs(fc)) - 0.5),(max(abs(fc)) + 0.5))) +
  scale_color_manual(values = c("#2600D1FF","#000000","#D60C00FF"), drop = F) +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_rect(colour = 'black', size = 1), legend.position = 'none', 
        plot.title = element_text(hjust = 0.5)) +
  xlab(bquote(~Log[2]~Fold~Change)) + ylab(bquote(~-Log[10]~Adjusted~p-Value)) +
  geom_hline(yintercept = -log10(0.05), linetype = 'dashed') +
  geom_vline(xintercept = -1, linetype = 'dashed') + geom_vline(xintercept = 1, linetype = 'dashed') + 
  geom_text_repel(aes(x = fc, y = pval, label = ifelse(sig != 0, lab, ''))) +
  ggtitle('States with more or less murder incidence with time')
vp1
```

Esta gráfica se puede mejorar:

```{r,warning=FALSE,message=FALSE}
vp1 <- ggplot(data = df, aes(x = fc, y = pval)) + 
  geom_point(aes(colour = sig), size = 3, alpha = 0.8, shape = 16) + 
  geom_point(data = subset(df, sig != 0), aes(colour = sig), size = 3.5, alpha = 1, shape = 16) +
  theme_classic(base_size = 12) + 
  scale_x_continuous(
    limits = c((-max(abs(fc)) - 0.5), (max(abs(fc)) + 0.5)),
    breaks = seq(-ceiling(max(abs(fc))), ceiling(max(abs(fc))), by = 1)
  ) +
  scale_y_continuous(expand = expansion(mult = c(0.02, 0.1))) +
  scale_color_manual(
    values = c("#3B4CC0", "#7F7F7F", "#B40426"),
    labels = c("Decreased", "Not significant", "Increased"),
    drop = FALSE
  ) +
  theme(
    panel.grid.major = element_blank(), 
    panel.grid.minor = element_blank(),
    panel.background = element_blank(),
    panel.border = element_rect(colour = 'black', fill = NA, size = 1.2),
    axis.line = element_blank(),
    axis.title.x = element_text(size = 14, face = "bold", margin = margin(t = 10)),
    axis.title.y = element_text(size = 14, face = "bold", margin = margin(r = 10)),
    axis.text = element_text(size = 11, colour = "black"),
    axis.ticks = element_line(colour = "black", size = 0.8),
    axis.ticks.length = unit(0.15, "cm"),
    plot.title = element_text(hjust = 0.5, size = 16, face = "bold", margin = margin(b = 15)),
    plot.margin = margin(15, 15, 15, 15),
    legend.position = "bottom", #c(0.85, 0.05),
    legend.title = element_blank(),
    legend.text = element_text(size = 10),
    legend.background = element_rect(fill = "white", colour = "black", size = 0.5),
    legend.key.size = unit(0.4, "cm"),
    legend.spacing.y = unit(0.1, "cm")
  ) +
  xlab(bquote(~Log[2]~"Fold Change")) + 
  ylab(bquote(~"-"*Log[10]~"Adjusted"~italic(P)*"-value")) +
  geom_hline(yintercept = -log10(0.05), linetype = 'dashed', colour = "#666666", size = 0.7) +
  geom_vline(xintercept = -1, linetype = 'dashed', colour = "#666666", size = 0.7) + 
  geom_vline(xintercept = 1, linetype = 'dashed', colour = "#666666", size = 0.7) + 
  geom_text_repel(
    aes(label = ifelse(sig != 0, lab, '')),
    size = 3.5,
    fontface = "bold",
    box.padding = 0.5,
    point.padding = 0.3,
    segment.color = "grey40",
    segment.size = 0.4,
    min.segment.length = 0,
    max.overlaps = 20,
    force = 2,
    seed = 42
  ) +
  ggtitle('States with differential murder incidence over time')
vp1
```



# Ejercicio 2

Este ejercicio corresponde al examen del curso 22/23. La única diferencia es que se han modificado los enunciado para que no sea "tan fácil".

Los datos de este ejercicio tratan sobre mensajes, distinguiendo entre mensajes deseados "HAM" y mensajes no deseados "SPAM". La base de datos incluye el contenido de cada mensaje.

**cargar los archivos spam.csv**

```{r}
data1 <- read.csv('./data/spam.csv', 
                  header = T, sep = ',', stringsAsFactors = F,
                  check.names = F, fileEncoding = 'latin1')
# Delete columns 3,4 and 5 (son columnas vacias)
data1 <- data1[,1:2]
colnames(data1) <- c('Class', 'Message')

```


**Modificar la columna 'Message' para que todas las letras estén en minúsculas. Se puede utilizar la función `tolower()`. También se pide quitar los signos de puntuación, dígitos y "stop words". Para esto utilizar la librería `tm`.**

Los "stop words" son palabras que no añaden información. En el campo de Procesamiento del Lenguaje (NPL) es uno de las etapas iniciales. Aunque parezca que se pierde información, la realidad es que estas palabras son inecesarias.

```{r}
data2 <- data1
data2[,2] <- tolower(data2[,2])
data2[,2] <- removePunctuation(data2[,2])
data2[,2] <- removeNumbers(data2[,2])
data2[,2] <- removeWords(data2[,2], stopwords("english"))
```


**Eliminar en la columna 'Message' las palabras que tengan menos de 3 letras**

```{r}
tmp <- unlist(strsplit(data2[,2], " "))
wordsL3 <- tmp[nchar(tmp)<=3]
tmp1 <- duplicated(wordsL3)
wordsL3 <- wordsL3[!duplicated(wordsL3)]
data2[,2] <- removeWords(data2[,2],wordsL3)
```


### 2.1

**Calcular para cada mensaje la longitud media de las palabras que forman el mensaje. Para esto, primero vamos a transformar cada palabra en su forma base (conocido como lema). Esto se puede hacer utilizando la función `lemmatize_words()`. Para calcular la media no se deben tener en cuenta palabras base con longitud menor a 3.**

A modo de ejemplo de como funciona esta función:

```{r}
lemmatize_words("driving")
# driving -> drive
```

```{r}
data2$mean <- 0
n <- dim(data2)[1]

for (i in 1:n){
  tmp <- unlist(strsplit(data2[i,2], " "))
  tmp <- lemmatize_words(tmp)
  tmp <- tmp[nchar(tmp)>3]
  tmp1 <- nchar(tmp)
  if (sum(tmp1>0)>0){
    tmp <- tmp[tmp1>0]
    tmp1 <- tmp1[tmp1>0]
  }
  data2$mean[i] <- mean(tmp1)
  data2$Message[i] <- paste(tmp, collapse=' ')
}
if(any(is.na(data2$mean))){
  data2 <- data2[!is.na(data2$mean),]   
}
```


### 2.2 

**¿la longitud media de las palabras que forman los mensajes (calculado en el apartado anterior) es diferente para los mensajes tipo "Spam" y tipo "Ham"? Realiza una gráfica para mostrar esta comparación.**

```{r}
idx_ham <- which(data2[,1]=='ham')
mean(data2$mean[idx_ham])
mean(data2$mean[-idx_ham])
```


```{r}
shapiro.test(data2$mean[idx_ham])
shapiro.test(data2$mean[-idx_ham])
```


```{r}
test <- wilcox.test(data2$mean[idx_ham], data2$mean[-idx_ham])
p.value <- round(test$p.value,68)
p.value

```

```{r,warning=FALSE,message=FALSE}
Fig1 <- ggplot(data2) +
  geom_density(aes(mean,fill=Class,
                   colour=Class),alpha=0.4, size =0.8) +
  scale_fill_manual(values=c('#0072B250','#D55E0050'))+
  scale_color_manual(values=c('#0072B2','#D55E00'))+
  theme_classic() + xlab('Length') + 
  geom_vline(xintercept = median(data2$mean[idx_ham]),
             linetype = 'dashed',
             colour='#0072B2', size=0.7) +
  geom_vline(xintercept = median(data2$mean[-idx_ham]),
             linetype = 'dashed',
             colour='#D55E00', size=0.7) +
  scale_y_continuous(expand = expansion(mult = c(0.01,0.01)))+
  xlim(0,10)+
  ggtitle('Density function of average word length per message') +
  theme(legend.title = element_blank(),
        axis.title.y = element_blank(),
        plot.title = element_text(hjust = 0.5, size= 12),
        axis.text.x = element_text(hjust = 0.9, vjust = 0.9), 
        axis.text.y = element_text(hjust = 0.9))

Fig1 <- Fig1 + geom_text(x = 8, y = 0.4,
                  label = paste0('Wilcoxon P-value: ',as.character(p.value)),
                  show.legend = F, size = 4)
Fig1
```


### 2.3

**Se pide construir una matriz Y que contenga para cada mensaje (fila) la cantidad de veces que aparece cada palabra (columnas). La matriz Y tendrá por tanto 5479 filas (número de mensajes) y xxx columnas (siendo xxx el número de palabras distintas**

```{r}
words <- unlist(strsplit(data2[,2], " "))
words <- words[!duplicated(words)]

n <- dim(data2)[1]
Y <- matrix(0, nrow=n, ncol=length(words))
colnames(Y) <- words


for (i in 1:n){
  tmp <- unlist(strsplit(data2[i,2], " "))
  tmp <- table(tmp)
  tmp <- as.data.frame(tmp)
  idx <- which(is.element(colnames(Y),tmp$tmp))
  Y[i,idx] <- as.numeric(tmp$Freq)
}
```


**Crear una matriz X que resulte de eliminar palabras que tengan una frecuencia menor a 50. Es decir, palabras que en total hayan aparecido menos de 50 veces. La matriz resultante debe tener 5479 filas y 119 columnas.**

```{r}
idx <- colSums(Y)>50
X <- Y[,idx]

```


**Realizar una gráfica en 2D que resuma, en la medida de lo posible, el máximo de información que contienen las columnas de la matriz X. En la gráfica debe distinguir entre los mensajes tipo "ham" y tipo "spam".**

```{r}
PCs <- prcomp(X, center = T, retx = T, scale=TRUE)
dim(PCs$rotation)

sum(PCs$sdev[1:2])/sum(PCs$sdev) #la varianza explicada

# Plot rotated data
data4 <- data.frame(PC1 = PCs$x[,1], PC2 = PCs$x[,2], Class = data2$Class)

Fig2 <- ggplot(data4, aes(x = PC1, y = PC2, colour = Class)) + 
  geom_point(size = 3.5, alpha = 0.7)+
  xlab('PC1') + ylab ('PC2') +
  theme_classic()+
  theme(legend.title = element_blank())
Fig2
```

**Con la información obtenida de la gráfica anterior, ¿hay algún eje de la gráfica donde se pueda distinguir entre los mensajes tipo "ham" y tipo "spam"? En caso de que sea así, ¿que variables de X son las que más influyen en ese eje?**

```{r}
idx <- which.max(PCs$rotation[,1])
colnames(X)[idx]
```

La palabra más importante es "prize". Las 5 palabras más importantes son:

```{r}
sort(PCs$rotation[,1],decreasing = TRUE)[1:5]
```


**¿Están estas 5 palabras relacionadas con que el mensaje sea "spam" o sea "ham"?**

```{r}

idx_ham <- which(data2[,1]=='ham')
compute_fisher <- function(X,word,idx_ham){
  # word <- "prize"
  iix <- match(word,colnames(X))
  df1 <- matrix(nrow = 2, ncol = 2)
  rownames(df1) <- c('Yes','No')
  colnames(df1) <- c('Spam','Ham')

  df1[1,1] <- sum(X[-idx_ham,iix]>0) 
  df1[2,1] <- sum(X[-idx_ham,iix]==0)

  df1[1,2] <- sum(X[idx_ham,iix]>0)  
  df1[2,2] <- sum(X[idx_ham,iix]==0)
  
  return(list(table= df1, fisher_test = fisher.test(df1)))
}

compute_fisher(X = X,word = "prize",idx_ham = idx_ham)
compute_fisher(X = X,word = "claim",idx_ham = idx_ham)
compute_fisher(X = X,word = "call",idx_ham = idx_ham)
compute_fisher(X = X,word = "urgent",idx_ham = idx_ham)
compute_fisher(X = X,word = "mobile",idx_ham = idx_ham)


```


# Ejercicio 3

Los datos de este ejercicio contiene información de los partidos de la liga 2018-2019.

**cargar los datos**

```{r}
dataF <- read.csv('./data/season-1819_csv.csv', 
                  header = T, sep = ',', stringsAsFactors = F,
                  check.names = F)
```


### 3.1

**Se pide evaluar para cada equipo si el hecho de jugar de local aumenta las posibilidades de ganar. Dar una lista, con una tasa de falsos positivos del 10%, de equipos en los que jugar de local influye en el hecho de ganar**

```{r}

fisher_test_laliga <- function(dataF,team){
  # team = "Barcelona"
  df2 <- matrix(0,nrow=2,ncol=2)
  rownames(df2) <- c('Win','Not Win')
  colnames(df2) <- c('Home','Away')
  
  idx_home <- which(dataF$HomeTeam==team)
  df2[1,1] <- sum(dataF$FTR[idx_home]=='H') 
  df2[2,1] <- sum(!dataF$FTR[idx_home]=='H')
  
  idx_away <- which(dataF$AwayTeam==team)
  df2[1,2] <- sum(dataF$FTR[idx_away]=='A') 
  df2[2,2] <- sum(!dataF$FTR[idx_away]=='A')
  
  test2 <- fisher.test(df2, alternative = 'greater')
  pvalue <- test2$p.value
  return(pvalue)
}

teams <- unique(dataF$HomeTeam)
pvalue <- sapply(teams,fisher_test_laliga,dataF=dataF)

pvalue_adj <- p.adjust(pvalue, 'fdr')
teams[pvalue_adj < 0.1]


```

### 3.2

**Se pide generar una gráfica en la que se muestre para cada equipo la proporción de victorias como local y como visitante.**


```{r}
data2 <- dataF %>%
  pivot_longer(
    cols = c(HomeTeam, AwayTeam), 
    names_to = "Place_Type",     
    values_to = "Team"          
  ) %>%
  
  mutate(
    Gano = case_when(
      Place_Type == 'HomeTeam' & FTR == 'H' ~ 1,
      Place_Type == 'AwayTeam' & FTR == 'A' ~ 1,
      .default = 0
    )
  ) %>%
  mutate(
    Place = if_else(Place_Type == 'HomeTeam', 'Home', 'Away')
  ) %>%
  group_by(Team, Place) %>%
  summarise(
    Wins = sum(Gano), # Sumar todos los '1' (Victorias) para el equipo y lugar
    .groups = 'drop'
  ) %>%
  select(Team, Wins, Place)
head(data2)
```


```{r}
bp1 <- ggplot(data = data2, aes(x = Team, y = Wins, fill = Place)) + 
  geom_bar(stat = 'identity',position="fill") + theme_classic() + coord_flip() + 
  scale_fill_manual(values = c("royalblue", "indianred"), 
                    guide = guide_legend(reverse = F)) + theme_classic() + 
  scale_y_continuous(expand = expansion(mult = c(0.01,0.02)), 
                     sec.axis = dup_axis()) +
  theme(axis.title.x=element_blank(), axis.title.y=element_blank(), legend.title=element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_rect(colour = "black", size = 1),
        axis.ticks.y = element_blank(), plot.title = element_text(hjust = 0.5,
                                                                  margin=margin(0,0,10,0), size = 11)) +
  ggtitle ('Wins per team - 2018-2019')
bp1
```

**Realizar también la gráfica mostrando el número total de victorias, distinguiendo entre las victorias como local y como visitante**

```{r}
bp2 <- ggplot(data = data2, aes(x = Team, y = Wins, fill = Place)) + 
  geom_bar(stat = 'identity') + theme_classic() + coord_flip() + 
  scale_fill_manual(values = c("royalblue", "indianred"), 
                    guide = guide_legend(reverse = F)) + theme_classic() + 
  scale_y_continuous(expand = expansion(mult = c(0.01,0.02)), 
                     sec.axis = dup_axis()) +
  theme(axis.title.x=element_blank(), axis.title.y=element_blank(), legend.title=element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_rect(colour = "black", size = 1),
        axis.ticks.y = element_blank(), plot.title = element_text(hjust = 0.5,
                                                                  margin=margin(0,0,10,0), size = 11)) +
  ggtitle ('Wins per team - 2018-2019')
bp2
```


### 3.3

**Las siguiente variables muestran caracteristicas sobre el rendimiento del equipo que jugó como visitante**

```{r}
cols1 <- c('AS', 'AST','AC', 'AF', 'FTAG', 'HTAG', 'AY')

```

**Se pide generar una tabla que contenga para cada equipo esta información, sumando el rendimiento en cada partido**

```{r}
idx_cols <- is.element(colnames(dataF), cols1)
data3 <- dataF[,idx_cols]
data3$Team <- dataF$AwayTeam


data4 <- aggregate(. ~ Team, data3, sum)
head(data4)
```

**Realizar una gráfica en 2D que maximice est información**

```{r}
m <- ncol(data4)
n <- nrow(data4)

X <- as.matrix(data4[,-1], nrow=n, ncol=m-1)

PCs <- prcomp(X, center = T, retx = T)

# Plot rotated data
data5 <- data.frame(PC1 = PCs$x[,1], PC2 = PCs$x[,2], Team = data4$Team)
Fig2 <- ggplot(data5) + geom_point(aes(x=PC1, y=PC2), size = 3) +
  xlab('PC1') + ylab ('PC2') + geom_text(aes(x=PC1, y=PC2,label=Team),hjust=0.5, vjust=2) +
  theme_classic()
Fig2
```


# Ejercicio 4

Este ejercicio corresponde al examen del curso 23/24. Se han modificado un poco las preguntas para que no sea "tan fácil".

### 4.1
**cargar los datos Residuos.csv.** <br>
**Eliminar la segunda columna "Total Nacional"** <br>
**Eliminar filas que contengan "missing values"** <br>
**Cambiar el nombre del data.frame a 'Tipo', 'Comunidad', 'Año', 'Total'** <br>
**1 punto** <br>

```{r}
data1 <- read.csv('data/Residuos.csv', 
                  header = T, sep = '\t', stringsAsFactors = F,
                  check.names = F)

data1 <- data1[,-2]
data1[data1==''] <- NA
data1 <- na.omit(data1)
colnames(data1) <- c('Tipo', 'Comunidad', 'Año', 'Total')

```


### 4.2

**Convierte la variable 'Total' en numérica, teniendo en cuenta que es necesario eliminar los "."**<br>
**Elimina el código numérico en las columnas 'Tipo' y 'Comunidad'**<br>

```{r}
data1$Total <- str_replace_all(data1$Total,'\\.','')
data1$Total <- as.numeric(data1$Total)

tmp <- unlist(str_split_fixed(data1$Tipo," ", 2))
data1$Tipo <- tmp[,2]
tmp <- unlist(str_split_fixed(data1$Comunidad," ", 2))
data1$Comunidad <- tmp[,2]
data1$Tipo <- str_replace(data1$Tipo, 'y 08.43 ','')
```


**Finalmente, ejecuta el siguiente código para tener los nombres de las comunidades más cómodos de leer**<br>
**2 puntos**<br>


```{r}
data1$Comunidad[data1$Comunidad =='Madrid, Comunidad de']= 'Madrid'
data1$Comunidad[data1$Comunidad =='Murcia, Región de']= 'Murcia'
data1$Comunidad[data1$Comunidad =='Asturias, Principado de']= 'Asturias'
data1$Comunidad[data1$Comunidad =='Navarra, Comunidad Foral de']= 'Navarra'
data1$Comunidad[data1$Comunidad =='Balears, Illes']= 'Islas Baleares'
data1$Comunidad[data1$Comunidad =='Rioja, La']= 'La Rioja'
```


### 4.3



**Resumir datos anteriores por año y comunidad, obteniendo para cada comunidad la cantidad total de residuos**<br>
**Leer el archivo 'Poblacion.csv'**<br>
**Normalizar la cantidad de residuos por la población de la comunidad. Unidades: Toneladas/persona.**<br><br>
**Realizar un gráfico para las siguientes comunidades:**<br>
```{r}
idx <- iso <- c('Madrid', 'Murcia', 'País Vasco', 'Islas Baleares', 'Cataluña', 'Navarra')
```
**En el que se muestre los los residuos normalizados por comunidad y año**<br>

```{r}
data3 <- aggregate(Total ~ Comunidad + Año, data1, FUN = sum)
data3$Poblacion <- 0

```

```{r}
data2 <- read.csv('./data/Poblacion.csv', 
                  header = T, sep = ',', stringsAsFactors = F,
                  check.names = F)
data2 <- data2[,-1]

for (i in 1:dim(data3)[1]){
  year <- data3$Año[i]
  caut <- data3$Comunidad[i]
  idx <- which(data2$Año==year & data2$Comunidad==caut)
  data3$Poblacion[i] <- data2$Total[idx] 
}
data3$Total_nor <- data3$Total/data3$Poblacion


```


```{r}
idx <- iso <- c('Madrid', 'Murcia', 'País Vasco', 'Islas Baleares', 'Cataluña', 'Navarra')
tmp <- data3[is.element(data3$Comunidad,iso),]

Fig1 <- ggplot(data = tmp, aes(x = Año, y = Total_nor, color = Comunidad)) +
  geom_line(linewidth=1)+ theme_classic()+
  theme(legend.title=element_blank(),
        legend.text = element_text(size = 10), 
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.background = element_rect(colour = "black", linewidth = 1),
        axis.text.y = element_text(size = 10, margin=margin(0,10,0,0)),
        axis.text.x = element_text(size = 10,
                                   angle = 45, hjust = 0.9),
        axis.title.x = element_text(margin=margin(10,0,0,0)),
        axis.title.y = element_text(margin=margin(0,10,0,0)),
        plot.title = element_text(hjust = 0.5, margin=margin(0,0,10,0),
                                  face = 'bold'))+
  ggtitle('Normalized waste per community and year') +
  xlab('Year') + ylab('Normalized waste (Tons/person)') +
  scale_x_continuous(name='Year', 
                     breaks=seq(2010,2021,1))

Fig1
```


### 4.4

**Evaluar la tendencia lineal de los residuos a lo largo del tiempo para cada comunidad utilizando la prueba de correlación (calcular el p.value para cada comunidad)**<br>
**Identificar qué comunidades muestran una disminución significativa en los residuos a lo largo del tiempo (FDR <= 0.05)**<br>
**2 puntos**


```{r}
caut <- unique(data3$Comunidad)
pvalue <- NULL
corr <- NULL
for (i in 1:length(caut)){
  tmp <- caut[i]
  idx <- which(data3$Comunidad==tmp)
  x <- data3$Año[idx] - min(data3$Año[idx])
  y <- data3$Total_nor[idx]
  t1 <- cor.test(x,y)
  corr[i] <- t1$estimate
  pvalue[i] <- t1$p.value
}

FDR <- p.adjust(pvalue, method='fdr')
idx <- which(FDR <= 0.05 & corr <= -0.2)
caut[idx]
```


### 4.5

En el apartado anterior estamos utilizando n=12 para la prueba de correlación.
¿Es eso suficiente para capturar una correlación negativa de 0.5, asumiendo alpha=0.05 y power=0.8.

```{r}
pwr.r.test(r=-0.5,power=0.80,sig.level=0.05,alternative="less")
```

